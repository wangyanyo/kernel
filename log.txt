1. 一开始只是装载第一个扇区的内容到内存，想要装载其他扇区需要在第一个扇区的代码中使用0x13中断。可以用ghex查看boot.bin的二进制
    内容，这里面是实际被放到磁盘里的数据。但是real mode没有文件的概念，它只会加载boot.bin的第一扇区的内容并执行。
2. 写了一个引导进32位保护模式的代码，但这个代码我没太看懂，因为我对x86汇编不是特别熟。我想通过chatgpt深入了解一下这个代码是如何
    工作的。
3. 装了一个交叉编译器的环境
4. 修改Makefile，boot.bin占0号扇区，第1～100扇区(暂时)存放我们的内核代码。内核代码是由多个二进制文件链接而成，首先将各个文件
    编译成elf二进制格式，接着编写ld文件配置链接规则，即代码起始位置是1M，格式为二进制文件，代码最开始的命令是_start，以及各个
    段的位置和字节对齐设置。同时为了字节对齐，我们让kernel.asm的代码占512字节，这样多个二进制文件就能链接成内核代码了。然后向
    os.bin中写入boot.bin和kernel.bin，我们的操作系统就做好了。
    首先电脑和会将0号扇区加载到内存，在内存的0x7c00位置执行我们的boot程序，boot程序中定义了32位保护模式，它首先设置段寄存器，
    然后进入32位保护模式，然后将1～100扇区的内容加载到内存，然后跳转到CODE_SEG:0x100000，开始执行内核代码。在kernel.asm
    中要标注global _start便于链接，同时还有extern kernel_main和C语言程序链接，他首先设置段寄存器，然后设置a20(兼容设置)，
    然后就转向kernel_main()函数。
    链接的时候要打标记，要不然是没办法进行跨文件格式跳转的，ld文件也不知道一开始的标注到底是哪个，但是如果知道代码地址的话那直接
    跳转就可以了，那为什么C语言文件之间没有标注却可以跳转呢？因为C语言的头文件就是标注，在编译时会找到头文件对应函数的地址。综上
    所述，如果要使用其他文件的代码，就必须要提前标注，这样才好链接。
4. 写了一个向终端打印字符串的函数，终端会打印0xB800后面的字符串，因此我们只要将字符串提前放到这个位置上，终端就会自动打印出来。
      我还以为打印要用到中断什么的，但是仔细一想单纯的的打印并不用和键盘交互，只需要把对应的内存交给显卡处理即可。
      还有就是内核编程很底层，它没办法使用大部分的库函数，甚至不能识别\n。但是好处是自由度更高，内核完全是计算机的主人，可以随便使
    用内存，比如前面的0xB800，我只要uint16_t* vedio_mem = 0xB800即可，不用分配内存，随便读写，而且都是真实的地址。我们平常说
    的分配内存是操作系统分配的，而我们本身就是操作系统。
      显卡输出字符要看两个字节，第一个字节是字符，第二个字节是颜色。我们将这两个字节放到vedio_mem的对应位置，该字符就在终端对应
    位置上打印出来了。想要输出一个字符串，我们还要维护一个坐标，每输出一个字符就更新坐标，遇到\n直接把行加一，列置零。然后获取字符
    串的长度，将字符串的字符依次打印出即可。按照上面的逻辑，还可以处理一下\t，只要让列变成下一个4的倍数即可。
5. 增加了一个向量描述符表，有两个结构idt_desc代表中断函数的属性，idtr_desc里面是中断函数的数量和中断函数表的起始地址，他们都遵循
    一个规则。写出初始化中断函数表和设置中断函数的方法，调用idt_load将其装载，使用lidt利用idtr_desc内的信息将函数表装载。然后
    中断函数就被更新了，可以使用 div 0 来检验。
    磁盘分布
      0～0x200       boot
      0x200~0x1200   text
      0x1200~0x2200   rodata
      0x2200~0x3200   data
      0x3200~0x4200   bss
      0x4200~0x5200   asm
      其中 0x200~0x400 是kernel.asm，0x400~0x1200是其他内核代码

    内存分布
      0x7c000   boot程序
      0x100000  内核代码，_start
6. 增加了in和out的函数，原理是使用汇编的in和out，暂时不知道怎么用，我对IO端口不是很熟。
7. 增加了对硬件中断处理的函数，硬件中断指的是键盘，定时器，硬盘这些。首先将硬件中断重新映射到以0x20为起始的中断表上，接下来对所有
    中断设置一个默认的中断处理程序。然后对想要设置的中断进行处理，比如键盘中断就是 0x20 + 0x1 = 0x21，那么我们设置0x21的中断
    程序是int21h，在汇编中定义，为什么要跳到汇编来呢？因为我们要禁用中断，因为我们不想嵌套中断；我们要保存所有寄存器；我们要有
    iret来表示这是一个中断程序，执行中断才会有的ret操作。在int21h中再调用int21_handler，在C语言中定义，这样就实现了一个硬件
    中断处理函数。
      其实内核就是应该用汇编来写，只不过汇编太难理解，所以我们在必要的时候才会使用汇编。就像上面的中断程序，有些操作只能在汇编里做，
    所以跳到汇编里，但是函数主体很复杂，用汇编很难写，所以再跳回C。
8. 内存分配这里没做太多检查，要是分配溢出了，或者释放非法地址，或者多个线程都需要分配内存时该怎么办？而且分配内存的时候很慢，要遍历
    整个内存池找到连续的块，优化思路是搞一个空白块的链表，但是这样在访存和释放时又会有问题。
      加入了内存管理机制，在boot程序后面存储了我们的页信息表，页信息表达了该页是否被占用，是否是第一个，后面还有没有连续的页。每次
    分配内存就返回连续的free页并打上标记，释放内存就将标记改为free，这样的实现非常简单易懂，但是也有上面三个缺点，1. 没做检查
    2. 无法同时应对多个内存请求 3. 效率不高
      为什么需要内核来管理内存呢？内存管理+分页虚拟内存 共同组成了linux进程的安全机制，它们两个是密不可分的。同时由内核来分配内存
    也更加方便，在用户程序眼里电脑里只有自己这一个进程，并且拥有完成的4GB内存，不需要考虑进程切换，也不需要考虑内存分布，内核给
    进程营造了一个自由、安全的环境。而在内核眼里，我要不断响应中断处理任务调度，内存管理，设备驱动等工作，而且物理内存也只有一部
    分能使用，还有考虑溢出的问题。总之内核的机制对于在其上的应用程序来说是有很大用处的。
9. 在初始化阶段我们希望禁用中断，所以编写了两个汇编函数专门用于启用中断和禁用中断，在kernel.asm的一开始禁用中断，在kernel.c的
    初始化结束后调用汇编的启用中断函数来恢复中断。我们还希望在任何启用中断的时间段，中断描述符表里是有东西的，而之前的程序有一段
    空窗期。
10. 分页还可以设置一些权限等信息，将物理内存隐藏起来，用户程序不知道发生了什么，不知道其他进程的存在，可以获得更大的内存。我们可以
    隐藏我们的boot程序和内核程序。可以保护程序代码，比如我们把代码部分设置为只读。
      cr0和cr3寄存器用于分页相关。
      增加了paging模块，采用二级页表，1024*1024*4096。首先在分配4kb内存作为一级页表，然后遍历一级页表的每一个项，给其赋值二级
    页表的entry。由于分页，内存分配返回的地址的后12位都为0，因此我们可以用高20位来保存映射，低12位来设置一些flag，比如读写权限，
    是否有效等等。创建完页表后，我们还要把页表的地址赋给cr3，这样是加载页表。同时将cr0 | 0x80000000，这样是启用页表。在内核的
    初始化阶段，我们要为内核创建4GB的页表，内核也是需要页表的。
11. 新建了配置页表的函数，可以建立一个虚拟地址页到物理地址页的映射。首先我知道为什么之前初始化的时候创建了全部页表，并为每一个虚拟
    地址都建立了映射，并且该映射指向它本身，这是因为一旦启用分页，所有的访存都要经过页表，我们想让内核即使进入分页状态也能和之前一样
    访问物理内存。第二，分页对内核来说只是一个映射，我可以让任意一个页成为另一个页的映射，但是我们不会那么自由，我们一般是让任意一个
    页地址成为被分配的内存页的映射，感觉这个映射对于内核来说可有可无，意义不明。第三，分页主要服务于多进程，每个进程都有自己的页表，
    每次切换进程时我们把页表地址赋给cr3，然后将 cr0 | 0x80000000 -> cr0 启用分页，就实现了进程地址空间的切换，用户进程不会一下
    子创建所有列表，虽然在进程眼里自己拥有完整的4GB，但是有很多页其实是没有对应的物理页的，并且进程的所有页都是内核的heap分配的。
12. 增加了一个可以从磁盘读数据的函数disk_read_sector(), 第一个参数代表起始扇区，第二个参数代表扇区数，第三个参数代表缓存地址。
    其流程和boot程序里加载内核代码的流程相同，就是通过一些固定的in, out来实现读磁盘。
13. 写了一个读磁盘的驱动程序，disk结构体里存储了磁盘的编号以及扇区大小。使用disk_search_and_init()函数来初始化磁盘驱动，使用
    disk_get()函数来获取对硬磁盘的disk结构地址，使用disk_read_blocks()函数读磁盘，底层原理就是利用之前写的读磁盘程序。但是
    我们只有一个磁盘，因此没有search的功能，也没有区分对于不同的磁盘作不同的操作，但是我们还是写了这些抽象的函数，为了日后扩展。
14. 文件系统提供了一个读写磁盘的抽象，磁盘本身是不知道文件系统的存在的。如果没有文件系统，我们将被迫使用扇区号来读取和写入磁盘，这
    是我们不想看到的。(如何把一个机器变成一个方便且可用的操作系统)
      实现了FAT文件系统，文件系统可以说是内核的难点之一，也是内核的关键部分。教程里的是FAT16文件系统，这个系统不是最好的，但是相对
    简单，我的计划是首先写出FAT16，然后在未来一个月之内更新 内存管理 和 文件系统，我想写一个类似linux的 ETX4 文件系统。
      如何设计文件系统呢？首先要在脑子里有个大致的模型，我的这个文件系统的核心功能是什么？最核心的功能就是我能通过文件路径找到磁盘
    里对应的文件。那么首先要做的就是对路径字符串的处理，我要从路径字符串里获取所有我想要的信息，包括其是否合法，其驱动器号等等。这些
    功能函数可以在一开始写出来，也可以在接下来的开发中需要什么就些什么。那么“接下来的开发”是指什么呢？当然是我的文件本身，我的文件
    的struct结构是怎么表示的？在磁盘中是怎么表示的？在内存中是怎么表示的？我的打开文件，关闭文件，读写文件这些基础功能该如何实现？
    我们要把路径字符串转为路径链表，类似词法分析，接下来我们就不会再用路径字符串了。
      这个 current_directory_path 好像没用到啊，这是什么当前地址吗？那取驱动器号和取前面的地址不应该从这个做起吗？或者说一开始
    将两个字符串连在一起。
      写内核尽量不要使用递归，因为内核中没有保护机制，我们绝对不想看到栈溢出的情况，那会使计算机崩溃。
      add-symbol-file ../build/kernelfull.o 0x100000
      target remote | qemu-system-i386 -hda ./os.bin -S -gdb stdio
15. 创建分页时过慢，接下来解决这个问题。主要是kzalloc()的memset太慢，我将char换成int，一次赋值4个字节。经过这样的优化后，速度
    确实快了一些。但最让我不解的是为什么一个 1024 * 1024 的循环跑了1s的时间？是模拟器太慢了吗？我clone了原作者的代码，发现他也
    有这个问题。
16. 增加了disk streamer，其实就是记录了一个磁盘的定位，类似指针。可以读取该“指针”后面制定字节数的数据。底层没有实质性的改变，
    只是从磁盘读数据更方便了。以前是读出几个扇区的内容，然后抛弃掉多余的。比如我要读第一扇区的中间字节，那么我会先把第一扇区读出来，
    然后单独取出中间的字节。而现在要做的只是给一个定位和驱动器号，就可以想读多少字节就读多少，而且读的过程中指针一直在向后移动，就
    像一个“流”，但底层的实现是没变的，这只是一个抽象。
      遇到了一个bug，通过 “输出中间值 + 猜 + 粘贴原作者代码” 的方式找到了错误发生处。在idt.c的第42行
      错误代码：idtr_descriptor.limit = KERNEL_TOTAL_INTERRUPTS;
      正确代码：idtr_descriptor.limit = sizeof(idt_descriptors) -1;
      像这种一定要小心设置，因为这是固定的，类似公式的东西。
17. 在引导程序里增加了FAT16头，加上这个之后，linux就可以识别出我这个os.bin是一个文件系统，然后就可以把linux的一个文件夹挂载到
    我的内核程序上。FAT16头包含了一些文件系统的基本信息，比如一个扇区多少字节，一个集群多少扇区，多少个保留扇区等等，也是类似公式
    的东西，这个一定不能写错。
18. VFS是虚拟文件系统的意思，它是一层操作文件的抽象。在插入磁盘时，它会检测该磁盘的文件系统，然后将磁盘和对应的文件系统进行绑定，
    绑定方法是，内核里一开始就有各种文件系统的fopen, fread, fwrite, fclose等等这些函数的定义，然后我的disk结构里有几个函数
    指针，然后我让这些函数指针指向对应的函数，这样就是实现了绑定。同时我用户在调用fopen的时候，我的内核会创建一个file结构，里面
    有这个文件的信息和绑定的文件系统函数，并且返回这个file的index，也就是文件描述符。这样用户就可以用这个文件描述符来申请fread,
    fwrite, fclose这些操作。如果没有VFS，我们就只能用一种文件系统，非常不灵活，我们不想要过渡耦合的代码，通过加入VFS中间层 + 
    函数指针绑定的方式，实现了灵活且优美的文件系统。很多耦合问题都提议通过增加中间层来解决。
      使用函数指针绑定类似面向对象里的多态，其实C++的很多语法都可以通过C来实现。
19. 新增了VFS，VFS允许我们的内核可以处理多种文件系统。filesystem有若干函数指针，指向实现fopen,fread,fwrite,fclose...的具体
    实现，也就是说filesystem是一个接口，可以指向不同的实现。我们有一个filesystem数组，代表内核能处理的所有文件系统，我们可以用
    fs_init()在内核初始化的时候加载文件系统，也可以使用fs_insert_filesystem()加载文件系统。我们可以用fs_resolve()给磁盘绑定
    对应的文件系统。同时我们还可以获取一个文件描述符，或者使用文件描述符访问对应的文件。文件描述符里有index, disk 和 filesystem，
    我估计还要加一个 streamer。
      总之，VFS是一层灵活的抽象，它可以让我们的内核使用多个文件系统。
20. 新增了fat16文件系统的框架，以及其与VFS的对接。写完接口定义后，接下来我们就要开始写fopen, fread, fwrite, fclose, fstat的
    实现细节，这是文件系统最关键的部分。
21. 新增了fat16相关的结构，其中包含了fat16_header用于识别fat16文件系统，fat16_header_extended存储一些扩展信息,fat16_h代表
    一个完整的fat16头。fat_directory_item定义了文件的属性；fat_directory代表文件夹，相较于fat_directory_item要额外存储一
    些东西；fat_item代表文件项，它指向文件夹或文件，通过一个类型变量来识别。如果用户要打开文件，我们返回fat_item_descriptor，
    里面有指向fat_item的指针。对于该磁盘的fat16系统，我们持有一个fat_private，目前作用未知。
      在设计结构的时候需要经验，什么时候用指针，什么时候不用。用指针更节省空间，但也更麻烦，比如需要释放空间或者多个对象共用同一块
    空间等等。
      通过 指针 + union + 函数指针 可以实现所有的面向对象特性。
22. 新增了fs_resolve()的实现，fs_resolve()干两件事，第一件是检查该磁盘是不是自己这个文件系统，方式是检查第一个扇区的文件系统的
    部分的flag；第二件事是初始化fat_private并赋给磁盘，首先初始化header，直接读磁盘即可，然后初始化三个流，然后初始化root文件，
    就是把对应位置的数读出来，然后计算出item数量，初始扇区，结束扇区这些。
23. 新增了fopen的VFS层的处理，什么是打开文件，就是我们内核要获取这个文件的信息，然后返回一个文件描述符的index。所以我们解析路径，
    解析文件打开模式，获取磁盘，检查磁盘的文件系统，然后使用磁盘的绑定的文件系统的fopen(disk, path, mode)函数获取文件的信息，
    有了disk, disk->filesystem, private后，我们就可以新建一个文件描述符并将上面三个赋给它，然后返回该文件描述符的index。以上
    是通用的fopen的流程，接下来要实现具体的fat16的fopen流程，我猜fat16文件夹里的文件的fat_directory_item都是放在一起的，且
    大小固定，所以就像类似字典树那样向下搜索就能找到我们想要的文件。
24. fat_item_descriptor->pos 有什么用？
      标注了几个可能的错误和值得优化的地方，就连原作者都会出错，我这样的小白肯定也在某些地方出错了，只是测试不够，检查不够，所以还未
    显现出来罢了。所以说每做完一个模块就再重复检查一下，看看有没有错误或值得优化的点。
      等到该fat16写完，我会将我标注出来的地方都改好。
      fat的fopen就是返回一个fat_item，首先就是按照路径一层层获取fat_item，用过的fat_item要free，直到找到最后的文件。那么如何
    获取fat_item呢？首先遍历当前目录的每一个项，算出其文件名并比对，找出相同的文件名；然后制作fat_item，首先根据其文件类型来做出
    不同的fat_item，如果是普通文件，那么只需复制当前的fat_directory_item即可，如果是文件夹，还要载入其目录所有项；首先算出总项
    数，算出要读取的字节数，然后便开始读取；每次读取，根据starting_cluster和offset找出应该读取的cluster，然后找到对应的位置，
    找到后开始读取，offset+=total_to_read, out+=total_to_read, 然后进行下一次读取，最终将所有目录项全部读取。
      最终VFS获得了fat_item，我们成功新建了一个文件描述符，我们知道这个文件存在，也知道的它的disk, fs 和fat_firectory_item里
    的信息，我们可以使用这些信息进行读写。fopen帮我们找到这个文件，并提供这个文件的信息，它占用内存，也占用文件描述符。
25. 写了fread, 从VFS角度看就是做一些参数检查，并且调用对应文件系统的fread; 对于fat16, 我们做的就是使用fat16_read_internal()
    读取起点为starting_cluster, 位置为offset, 大小为size的数据，做nmemb次循环。我认为读完要更新pos, 但是原作者没更新。
      还有就是根目录的ending_sector_pos是有用的，它是cluster的起点，我通过检查ghex发现了这一点。
26. 新增了fseek，其实就是修改pos的值，文件描述符记录了文件的所有信息，除了文件内容。
27. 函数指针 + void* private 实现了继承和多态。函数指针实现了虚函数，void* private 实现了子类的独有成员。也就是说可以将一个类
    配置成完全不同的版本，函数指针指向该版本的函数，void* private 指向该版本独有的数据成员。
28. 增加了fstat，他返回文件的状态，比如是不是只读，是不是可执行的等；还返回文件的大小。我们使用 ls -l 命令时就会调用fstat。
29. User land 用户态能实现的最基本的条件是处理器的四个等级，ring 0, ring 1, ring 2, ring 3，User land 位于 ring 3，在
    ring 3 等级很多指令时没办法执行的，比如更改中断描述符表，更换页表，以及直接访问硬件的 in 或 out 指令，这就使得User land没
    办法修改内核的中断函数，没办法主动切换到其他进程，没办法直接访问硬件；以上再加上内存分配和页表，限制了User land对内存的访问，
    这样就使得用户进程是安全的，它没办法直接访问硬件，没办法随意访问内存，没办法影响内核的状态，没办法影响其他进程。
      用户进程不是特殊的进程，无论是用户进程还是内核进程都是同样的结构，即Task。User land只是描述了执行用户进程时处理器的状态，
    此时处理器限制等级是ring 3, 页表是当前进程的页表。这是User land的本质。
      我们切换进程时，只是切换页表和寄存器，切换页表也只是将页表的地址赋给cr3，并不是什么很费时间的操作。甚至多个进程可以有共享内存，
    只要让页表映射到同一位置即可。
      其实中断这里和gdt这里不太明白，gdt是切换到保护模式用的，这里还是不太理解，当时只是在照做，这个gdt究竟有什么用呢？为什么切换
    到保护模式就需要这个gdt呢？我记得实模式是16位的，当时想切换到32位所以进入了保护模式，这里还要再学习一下。
      又看了一遍这节课，很多东西伏羲了一下，也了解到了很多新的东西，但还有一点我不明白。那就是“假装从中断返回“是什么意思？这么做有
    什么意义？
      GDT和IDT那里还是不熟悉，需要看一下osdev和重新梳理一下代码。我这个习惯很不好，不熟悉的东西应该马上把它搞明白，而不是直接跳过，
    就算不精通也可以，但至少要知道“这个东西是干什么的？”，“如果没有这个东西会怎么样？”，“这个东西和其他模块的联系“ 
      我还想重新梳理一下整个程序，要把每个地方都搞懂，把每个模块的逻辑搞清楚，其中有些模块有问题，还要总结一下。
30. 用C语言实现了设置并加载GDT的操作，课程中说GDT是来描述地址空间的，难道这个也和User land有关吗？想知道这些，首先还是要彻底搞懂
    gdt是什么。
      还有就是我的项目开发的效率还有转化率不高，看课->总结->自己动手写->对照修改->下一步的展望，想试一下这个流程，感觉如果能在45分
    钟内一气呵成做完的话，效率和转化率都会很高，但考虑到一节课就将近20分钟，感觉需要两个学习段才能做完。
      看完10页CSAPP就做项目，每天三次贡献，重复上面的流程，大概需要5个小时。做完这些我还想看osdev，每天看三个主题。然后我想看
    Linux内核分析与实现，每天看10页。
      约束自己，高效学习，合理制定计划，保持精力。优先解决各种生理问题，然后再考虑其他的。
      买个坐垫，多喝水，多睡觉，每隔45分钟就活动15分钟，吃饭细嚼慢咽，不要打胶。让自己进入一个正向的循环。
31. 我大概理解GDT的用处了，GDT是用来描述一个段的。CSAPP有介绍过，x86架构默认使用分段，但是Linux想用纯粹的分页，这个要怎么实现呢？
    很简单，不论是代码段还是数据段，我都让他们的起始位置为0x00，Size为0xffffffff，这样就构建了一个不用分段，纯粹分页的32位地址
    空间，也就是说x86的 Protected Mode 的访存，默认先分段，后分页，我们把一个段扩充至整个地址空间，那么就只有分页了。这也是我们设
    置GDT的原因，因为访存时要先访问GDT，GDT的位置存在gdtr里，偏移量存在ltr里。
      这就是知识的串联，我终于搞懂GDT是什么东西了，这源于我在各方面学习的知识串联起来的结果，就像吹一个长气球，一下子肯定吹不出来，
    但是我可以一点一点吹出其中一小段，然后把他们串联起来，这样气球就好吹了。
      但是还有一处不解，那就是那个type有什么用？想搞懂这一点还是要看osdev。 
    增加了tss，即Task Switch Segment，具体作用未知，里面存储了大部分的寄存器信息，好像是用于恢复内和执行状态用的，总之是和进程
    切换相关。创建完tss结构后，还要编写tss_load()函数，实际上是设置ltr内的偏移量。然后我们要在kernel.c中创建tss，并将其放入到
    GDT中，而且GDT中还要新增用户代码段和用户数据段。
      难道说，所有的用户进程都要有一个对应的tss吗？是这样的。Intel的CPU提供了任务切换的功能。
      每个进程都有一个TSS，ltr里存储的是当前进程的TSS在GDT表里的偏移量，因为前面有5个GDT entry，因此新增的这个TSS的偏移量就是
    40, 新增的这个TSS描述的是内核进程。
      使用TSS来进行任务切换是Intel给我们的便利，只需一个命令就可以完成任务切换(只需写回当前TSS，加载目标TSS)，但是时间较长，一次
    切换要花费200周期且移植性差，不能在其他厂商的芯片上运行。现在的OS都是通过切换堆栈的方式完成任务切换，这也是我未来的更新目标。
32. 增加了task模块，task是一个链表结构，增加了新建，删除，返回下一个任务，返回当前任务的函数，可以说是建了一个task的框架。但是还有
    一些问题，我记录在 warning 中了，待修改。并且原作者的链表删除函数有bug，我将其修改了。如果在头文件中少加分号的话会出现莫名其妙
    的大量错误，特此记录。
33. 意识到了一个问题，那就是如果日后要更新内存管理，并将其修改成不连续的申请内存。那就有很多地方都要改，因为在内核代码中申请完空间
    没有建立内存映射, 因此在内核代码看来申请的空间是不连续的, 而用户态由于有页表映射，所以没有这个问题。那是不是说内核必须申请连续
    的空间, 而用户程序则无所谓呢? 日后更新内存管理的时候要考虑到这一点.
      新增了process，主要流程就是把二进制文件读出来，然后进行内存映射和寄存器设置，内存映射是paging_map_to(), task_init()设置
    了寄存器的初始值。令我疑惑的是，目前用户栈既没有映射，也没有赋值给栈寄存器。
      还有一个让我疑惑的点就是config.h中设置的栈地址是0x3ff000，小于0x400000，我怀疑这个是内核栈，但是内核空间不是在高地址空间
    吗？还是说内核栈是特殊的，它就是在低地址空间，.text之前的？
      没什么好说的，补充上次的代码，有几个原作者有错误的点，日后要多加留意。
34. 我终于搞懂哪个0x23和0x1b是干什么的了，这个0x23是0x20 + 3, 0x20是因为user data segment的gdt是第5个，所以偏移量是0x20
    因为gdt的偏移量是8的倍数，所以低三位都是0，所以用低两位来存储CPL，user land的CPL是3，所以是0x20 + 3 = 0x23
      看了最新版本的代码，有几个确实是作者写的有问题，但是它并没有全都改好，我还发现了另外几个错误。之后我要把他们写到issue里。
      我们想要从内核态进入用户态，什么时候会出现这样的转变呢？我们注意到中断返回时计算机会从内核态切换到用户态。所以我们初始化完内核
    后，我们伪造一个中断返回，我们向栈中push对应的用户态的上下文(其中包含用户态的页表, gdt, CPL等)，然后使用iretd进行中断返回，
    这样我们就从内核态进入用户态了。
35. 写了一个无限循环的用户程序，主要工作在于链接和写make文件。
    i686-elf-gcc -g -T ./linker.ld -o ./blank.bin -ffreestanding -O0 -nostdlib -fpic -g ./build/blank.o
    cd ./programs/blank && $(MAKE) all
    上面这两句有点疑惑，第一个为什么已经生成可执行文件了但还是要再链接一次？第二个后面的 && 和 $(MAKE) 没看懂，这是make的语法
    吗？还要再学一下make。
36. 现在我们要做的就是加载第一个进程。过程是调用process_load()，它创建并初始化process结构，并将其放入进程表中，同时还会创建一个
    task, task中的主要内容有页表、registers，registers里面有通用寄存器，段寄存器，栈指针，ip等。process_load()还会加载可执
    行程序到内存中，virt对应0x400000，pyhs对应process->ptr，建立内存映射。也就是说process_load之后，页表准备好了，程序进入
    内存了，task页准备好了。接下来就是加载task并进入user_land，方式是伪造一个中断返回，假设当前处于中断中，先更新页表，然后将
    一些特殊寄存器压到栈里，然后设置通用寄存器，然后执行中断返回，这样我们就进入了user_land，并开始执行我们写的用户程序。

    请时刻注意，我们开发的并不是linux内核，它只是一个能实现基础功能的内核。为了教学方便，它的很多模块采用的低效、古老但是简单的实现
    方法。我的计划是通过写完这个最基础的版本作为我内核的入门，并且完全理解这个版本，在此版本的基础上将核心功能一步步向Linux靠拢。
    因此在遇到该项目中的实现方法与Linux不同时，不要焦虑，要意识到这个版本只是最基础的内核。要思考该版本的不足之处，并思考Linux的
    机制是如何实现的，不要混淆。

      就比如，kernel的加载是将可执行文件加载到内存，然后建立映射，然后加载页表，然后将该程序的上下文推到栈中或加载到寄存器中，然后中
    断返回，这样就完成了一个程序的加载；而Linux的加载则不同，它会先建立一个区域映射，哪个区域对应哪个文件的哪个部分，然后同样也是将
    进程的上下文推入栈中或加载到寄存器，然后中断返回，运行时再按需分配页面。
      还有kernel的process_load()包含了创建进程，创建页表，创建任务，以及加载可执行文件，可以说是把所有的工作都包揽了；
      而Linux则分成了两步，fork()和exec()，fork()用于创建一个新进程，它会复制父进程的页表，分配一个新的pid，用写时复制技术保证
    父子进程的隔离性。exec()负责建立区域映射，将区域映射到对应的文件，同时设置一些标志位来表示这些区域的状态，然后具体的物理页面时
    按需分配的，即访问到时才会从磁盘中加载出来。
      同样是从内核态进入用户态并运行可执行文件。两个内核的执行过程不同，Linux的机制肯定是更优秀的，注意辨别，不要混淆。虽然该内核
    的机制不如Linux，但是同样实现了目的，这便是好的，但是未来还是要向Linux不断靠拢。

      即使这是一个最基础版本的内核，但是它的一些细节还是让我不太理解，比如刚才就发现一个bug，直接导致我的模拟器一直死机重启。
    错误代码：
      tss.esp = 0x600000;
      tss.ss = KERNEL_DATA_SELECTOR;
    正确代码：
      tss.esp0 = 0x600000;
      tss.ss0 = KERNEL_DATA_SELECTOR;
    esp0和ss0好像是分别代表内核栈和内核数据段，我把他们改成esp和ss就导致模拟器死机。这说明我对这些底层的东西不是很熟悉，那唯一的
    办法就是重新梳理代码并学习osdev上的知识。
      而且遇到问题不要跳过，要重复观看课程或重复翻阅书本，并且在网上找对应的解答。不要带着一个模糊的概念往下学习，起码要有一个清晰的
    印象。
37. 接下来是从用户态进入内核态，通过trap(原作者说是中断，我觉得不精确)进入内核态。之前我们中断返回的时候将task中存储的寄存器推到
    栈里，然后执行iretd中断返回进入User Land，但是那是我们伪造的中断返回。而这次我们是由用户态进入内核态再返回该进程的的用户态，
    所以我们再进入内核态的第一时间就把当前寄存器值压入栈中，然后中断函数执行结束后，将这些栈中的寄存器值放回去，iretd回到用户态。
      还有注册函数，这是在我网络编程后第二次接触注册函数，我很好奇注册函数做了什么。其实就是设置一个函数指针数组，让我们可以用数组
    的格式去调用与数字相关联的函数(比如中断号)，这样我们就不用使用复杂的函数名，使代码更加简洁。
      感觉 task_get_stack_item 有点问题，页表之间的转换有点绕，而且他把一个栈顶的元素解释成了 void*，我不能理解。
      void *task_get_stack_item(struct task* task, int index)
      {
        void *result = 0;
        ASSERT(is_kernel_page());
        uint32_t *sp_ptr = (uint32_t *)task->registers.esp;
        task_page_task(task);
        result = (void *)sp_ptr[index];
        kernel_page();
        return result;
      }
      先是在内核页表下获得了esp的值，然后切到用户页表，然后将栈的第index个元素的值转成void*并赋给result, 然后切回内核页表，返回
      result。我猜esp应该指向的是用户栈，要不然没必要切回到用户态，然后得到用户栈的第index值后，他把这个值再转成void*是我不能理
      解的，从函数名上来说应该是获取栈中的元素，但是为什么要翻译成void*呢？切回内核页表时可以理解的，因为这个函数就是在内核态执行
      的。 
38. 我终于知道 push ebp
             mov ebp, esp 的目的是什么了，就是为了访问参数。正常来说栈中先是参数，然后是栈指针，虽然可以通过esp加一个偏移量访问
    到这些参数，但是esp是变化的，这就增加了编译器的复杂性，所以我们选择通过edp来访问参数，所以在函数一开始我们保存原来的ebp，将esp
    赋给ebp，接下来都通过ebp来访问参数，最后 pop ebp。
      ss 是 stack segment 的意思，是栈段的寄存器，在kernel中是数据段的偏移量+CPL，kernel是忽略栈寻址的。
    这一节写的是系统调用的处理函数，首先pushad将当前用户程序的状态压到栈里；然后切换到内核态：将段寄存器切换到内核数据段gdt偏移量，
    然后加载内核页表；接着保存用户态状态：把栈里的寄存器赋给current_task->registers, 其实就给进程一个独占处理器的幻觉，它察觉不
    到自己被中断了；然后根据commnd进行分流，执行对应的处理程序；最后加载用户数据段寄存器偏移量，加载用户页表，popad，iretd返回
    current_task的用户态。
39. 中断号不够用怎么办？原作者的方法是系统调用触发的都是0x80中断号，然后将具体的commnd标识放到eax里，通过这样一个二级操作，就避免
    了在遥远的未来可能会出现的中断号不够的情况。
      系统调用其实就是两条线，加上一些后期的补丁连接，第一条线是调用，即在用户程序中执行int 80h，然后控制权跳到80h绑定的isr80h_
    wapper()函数，在该函数里进入内核态，执行command对应的操作，然后返回用户态恢复控制权；第二条线就是在kernel初始化的时候就绑定
    command编号和对应的系统调用操作；后期的补丁就是后期加上新的系统调用并注册。
40. [debug 日志]
      系统调用出了一点问题，看上去就是我在一直重复的执行系统调用，但是我的用户程序只申请了一次。
      并不是内核重启，如果是的话，屏幕会频繁的闪烁。
      我想试试不依靠原作者的程序，单靠我对kernel的理解，能不能找到这个bug。
      好吧，我是sb，用户程序那里应该是 jmp $，而我写的是 jmp label，这样就是一个循环。
      label:
        mov eax, 0
        int 0x80
        jmp $
      运行gdb
        add-symbol-file ../build/kernelfull.o
        break *0x400000
        target remote | qemu-system-i386 -hda ./os.bin -S -gdb stdio
        c
        layout asm
        stepi
        ...
        通过上面的步骤，证明了我这个程序是运行无误的，最起码是真正执行了系统调用。
41. 现在想将用户空间的一个字符串复制到内核空间，由于二者拥有不同的页表，地址不互通，所以这件事没有那么容易。首先申请一个页空间tmp,
    然后定位用户空间内不包含virtual的一个页addr(默认为tmp), 然后找到用户空间内addr对应的old_entry, 然后将addr映射到tmp, 将
    virtual的字符串复制到tmp, 然后加载内核页表(因为只有在内核页表内才能设置用户空间的页表)，然后将addr的映射恢复到old_entry,
    最后将tmp的字符串复制到phys, 释放tmp。
      新建了一个paging_get, 用于获取对应页表的对应地址的entry.    
      这一节也有许多小问题。
42. 增加了打印字符串的系统调用，框架搭好了，都是用的之前的东西。但是还有一个问题，我的学习历程太不连贯了，导致我现在对这个项目逐渐
    不熟，虽然很多概念搞懂了，但是知识体系没有很好构建出来，这一点之后要注意。以后每天看三节课，课课总结；而且这只是初期的kernel，
    以后还会继续扩展，在那个时候再接着搭建知识体系。
43. 学习了读取键盘输入的课程，每按一次键盘都会触发一次中断，对应 0x1, 在我们的中断表中就是 0x21。触发中断的同时会有一个scancode,
    我们根据这个scancode找出对应的ascii码。每个进程都有一个keyborad结构，其中包含一个循环队列，由其中的head和tail维护。每次
    push对应的进程是我们当前的进程，每次pop对应的进程是正在运行的进程，push和pop是分开的，中断处理函数应该push之后就结束，但是我
    不知道这个pop是什么时候触发的。同时和VFS一样，我们还要编写一个虚拟键盘层，以便兼容更多键盘类型，比如鼠标点击的键盘，自动键盘，
    或者不同厂商的键盘。
44. 新增了keyboard_init()，用于初始化各种厂商的keyboard。创建了keyboard类型，该类型是一个链表结构，里面包含了名字和init函数，
    估计keyboard_init()初始化keyboard, 绑定init函数，然后向这个链表添加节点。
      添加了keyborad的push, pop 和 backspace, process有一个keyboard_buffer结构，里面是一个循环队列。由于键盘输入的字符的
    ascii码不会是0, 依据这一特性可以很轻松的判断队列是空还是满，所以push, pop 和 backspace 也都很简单。这一还有一个技术，就是
    head 和 tail 递增时不会进行模运算，而是等到真正用到时再模运算，算出在队列数组的真实位置，我以前没这样做过，这样在数学上来讲是
    没问题的，降低了编码难度，再加上队列里不会出现0的特性，能够轻松的判断溢出，最终使这个循环队列简单又准确。
45. 在makefile上犯了点小错误，在下面增加了编译指令，但是没在FILS里加入相应的可重定向文件，下次注意。
    这一章增加了ps2键盘的keyboard结构，并在其init函数中启用ps2。然后将该结构加到keyboard链表里。然后增加了scancode转换ascii码
    的函数，接下来还有几个问题，第一个就是处理键盘中断，第二是设置一个大小写状态，第三就是怎么区分正在显示的进程和正在运行的任务。第
    四就是什么时候pop。
      但是原作者要更新一下中断处理模块，以便于实现键盘功能，我很好奇他会更新什么。
46. 利用汇编宏预写出512个中断入口函数，然后经过处理后转到interrupt_handler中统一处理，0x80是特殊的。通过编译宏预写，简化了代码，
    增强了可读性；通过统一处理，使代码更有条理，看起来不那么乱，而且更方便。
47. 32号中断
      32号中断即0x20, 是定时器中断。
    add-symbol-file filename address
      该指令用于添加可重定向文件的符号表，后面是可重定向文件名以及该文件被加载的初始地址，可以用于辅助打断点。如果没有该符号表，那么
      在gdb里 break kernel.c:100 是不合法的，因为没有符号表和address就找不到kernel.c的位置，也找不到第100行的位置，但是
      break 0x400000 是合法的，当PC为0x400000，程序就暂停执行。
    什么是io port, io port和网络端口的区别，进程间沟通也要用到端口，这三者的区别。
    键盘模块的完整设计思路。
      
48. 该节用于实验
    实验一: 当cpu处于内核态会响应定时器中断吗？
      实验步骤: 注册完中断之后启用中断，然后执行一个无限循环。
        idt_register_interrupt_callback(0x20, pic_timer_callback);
        enable_interrupts();
        while(1){}
      预期结果: 如果在内核态可以响应定时器中断，那么在屏幕上会打印东西。
      实验结果:1.屏幕打印No current task, 我怀疑是有响应中断的
              2.我在idt.c的interrupt_handler()截断，输出interrupt
              3.成功运行，屏幕上无限打印32，说明在内核态成功响应了定时器中断
      总结: 1.是否响应中断和CPU状态无关，只与当前是否启用中断有关，即cli
            2. 如果执行完中断后不执行outb(0x20, 0x20), 那CPU将不再响应中断

    实验二: 通过gdb探究从用户程序执行一个系统调用的全过程
      实验步骤：我们关注其中几个寄存器
        1. 在blank.asm的第一句, 我们查看寄存器，其中:
          esp   0x3ff000
          eip   0x400000
          cs    0x1b
          ss    0x23
          ds    0x23
          es    0x23
          fs    0x23
          gs    0x23
          cr0   0x80000011  [ PG ET PE]
          cr3   0x1413000
        2. 在 int 0x80 之前，我们查看寄存器，其中:
          esp   0x3feffc
          eip   0x40000a
          cs    0x1b
          ss... 0x23
          cr0   0x80000011
          cr3   0x1413000
        3. 在 int 0x80 之后，我们查看寄存器，其中:
          esp   0x5fffec    这是我们设置的内核栈的位置，tss.esp0 = 0x600000
          eip   0x10500f    boot将内核程序加载到0x100000起始的位置，在用户程序中，该位置的页表是线性映射的，因此可以安全地跳转
                            到该位置，同时因为中断调用，esp变成tss里设置的内核栈的位置，cs和ss等段寄存器指向了内核段，因此拥有
                            了跳转到该位置的权限。(内核的esp存在哪未知，可能就在tss里？)
          cs    0x8
          ss... 0x10
          cr3   0x1413000
        4. 调用kernel_page()前，我们查看寄存器，其中:
          esp   0x5fffa4
          eip   0x1012eb
          cs    0x8
          ss... 0x10
          cr3   0x1413000
        5. 调用paging_load_directory()后，我们查看寄存器，其中: 
          esp   0x5fff64
          eip   0x101b22
          cs    0x8
          ss... 0x10
          cr3   0x1004000     可以看到页表更新为内核页表，可以线性且随意访问内存了
        6. 调用task_page_task()前, 我们查看寄存器, 其中:
            背景: 中断的参数在用户栈里, 我们把它取出来
          esp   0x5ffb04
          eip   0x10446d
          cs    0x8
          ss... 0x10
          cr3   0x1004000
        7. 调用task_page_task()后, 我们查看寄存器, 其中:
          esp   0x5ffb04      这里的栈指针仍然指向内核栈, 我们是要从用户栈里取数据, 用户栈的地址可以从task结构中获取
          eip   0x1.....
          cs    0x8
          ss    0x10
          ds... 0x23          ss仍然是内核数据段, 但是ds,es,fs,gs指向是用户数据段, ss是stack segment, 因为esp仍然指向
                              内核栈, ss仍然是内核数据段?
          cr3   0x1413000     可以看到现在是用户页表
          在执行完task_page_task()之后, 我们仍然要用到内核栈，如下:
            mov    0x24(%esp),%eax    index -> eax
            lea    0x0(,%eax,4),%edx  index*4 -> edx
            mov    0x8(%esp),%eax     sp_ptr -> eax
            add    %edx,%eax          sp_ptr + index*4 -> eax
            mov    (%eax),%eax        (eax) -> eax
            mov    %eax,0xc(%esp)     eax -> result
            
            哎呀，好奇怪啊，为什么内核态中栈地址是0x600000，在用户态中栈地址仍然是0x600000？如果有多个进程呢？还是说内核栈是公共
          的？为什么切换页表后有些地址仍能正常访问？这和我了解到的知识不符。
            可以看到，sp_ptr和index都被存储在内核栈中，所以我们的esp和ss要保留内核态。我们先用内核栈的数据算出用户栈参数的地址，然
          后访存，由于我们访问的是用户栈，所以要提前将页表设置为用户页表。访问用户栈不代表更新esp，我们可以在内核栈的基础上算出地址，
          然后在用户页表的基础上访存从而得到用户栈的数据。
          
            内核代码地址空间:
            ----------0x100000----------
            内核代码，数据
            ----------------------------
            内核栈
            ----------0x600000----------

            用户代码地址空间: 虚拟地址
            ----------0x000000----------
            ----------------------------
            用户栈                       -> 对应物理地址内存池的一块内存，但是这个栈的位置有点奇怪，它是在低地址空间
            ----------0x3ff000----------
            ----------0x400000----------
            用户代码，数据，堆             -> 对应物理地址内存池的一块内存
            ----------------------------

        8. 调用kernel_page()后，我们查看寄存器，其中:
          esp   0x5ffb14
          eip   0x104491
          cs    0x8
          ss... 0x10
          cr3   0x1004000     这里又回到了内核页表

        ...
        
        9. 执行完isr80h_handler()后，我们查看寄存器，其中:
          esp   0x5fffc4      内核栈
          eip   0x10501c      内核代码
          cs    0x8
          ss... 0x10
          cr3   0x1413000     用户页表

        10. 执行完iret后，我们查看寄存器，其中:
          esp   0x3feffc      用户栈
          eip   0x40000c      用户代码
          cs    0x1b
          ss... 0x23
          cr3   0x1413000     用户页表
        
        由上面的实验其实就能了解中断、以及内核用户态的转换究竟发生了什么，内核态和用户态是很灵活的，并没有很严格的界限，最重要的五个
        寄存器就是esp, eip, cs, ss..., cr0和cr3寄存器用于分页相关。
          明天还想看一下中断返回究竟发生了什么，以及在用户页表基础下跳到内核代码时，究竟发生了什么，是碰巧正确运行的吗？
49. keyboard被设置成一个系统调用，将keyboard_pop()包装成一个系统调用，那pop就是一个事件驱动，而不是循环。
      还有就是我的键盘不是ps2啊，为什么这个scancode还是准确的?
      现在已经能更加熟练的使用gdb了，打印寄存器是print $eax，但是还是不知道怎么layout源码。调试的时候应该有个调试的思路。
50. 实现了putchar函数，本质上是系统调用，跳到terminal_writechar函数，把字符打印到屏幕上这种和硬件交互的工作，确实应该交给内核来
    做，包装成系统调用没问题。但是，据我所知，输入输出不是和stdin和stdout有关吗？从stdin中读取，然后再输出到stdout。在该程序中从
    键盘中读取，再输出到屏幕上，难道说是把键盘看作stdin，把屏幕看作stdout？还是说应该在加一个中间层？即: 
            键盘 -> stdin -> user_tmp -> stdout -> 屏幕
    看看在之后的课程有没有其他输入输出函数吧，尤其是和文件相关的，我是想把这个内核向linux上靠的，这个kernel将是我的心血。
51. 当前有几个疑问:
      1. 为什么执行 int 0x80 后，能在用户页表的基础上跳转到内核代码。
      2. 如果每个进程都拥有一个内核栈，那执行中断handler时，要不要切换到线性内核页表？如果切换，那内核栈地址是不是也要一起切换？
        如果不切换，那怎么访问内核在 heap 中创建的数据结构？
      3. iret 和 TSS 之间的关系

    我想重新调试一下中断过程，而且我怀疑作者在写process相关代码时根本就没有考虑过多进程，因为很多情况都是碰巧发生不具有普遍性的，比
    如说，无论是在内核页表下还是用户页表下，内核栈的位置都是0x6000000，如果有多个进程同时执行系统调用，很明显这会出问题。作者可能就
    是只做了user_land + paging，没有考虑 multitask。
      在我的印象中，用户态切到内核态是要切换页表的，因为内核能访问所有内存，而且有些数据结构就是存在0~3G这个地址空间的。但是虚拟内存
    的内核空间肯定是经过映射的，也就是是说映射后，内核空间的内核栈可能就不是那个高地址了，甚至有可能是离散的。也就是说页表切换带来了
    很多问题，因为页表的隔离性太强了，而内核态和用户态又有着很深的联系。比如说在用户页表内，内核栈是在内核空间的，但是切换到一个线性
    页表后，内核栈就在不固定的位置了。我现在急切地要看Linux的代码，我想知道官方是怎么做的，大家认可的方法是什么。
      首先看下地址结构，首先是内核的物理地址:
        ---------0x00B8000----------
        text buffer
        ----------------------------
                    ...
        ---------0x0100000----------
        内核代码，数据
        ----------------------------
        初始内核栈
        ---------0x0200000----------
        ----------------------------
        TSS内核栈
        ---------0x0600000----------
        某些硬件映射区
        ---------0x1000000----------
        heap
        ---------0x7400000----------

        接下来是我们唯一的用户程序的虚拟地址空间:
        ---------0x0000000----------
        线性映射，有效                -> 这里很奇怪，按理说应该是无效映射
        ---------0x03fb000----------
        用户栈, 16kb                 -> 对应物理地址内存池的一块内存，但是这个栈的位置有点奇怪，它是在低地址空间
        ---------0x03ff000----------
        空闲页, 4kb
        ---------0x0400000----------
        用户代码，数据，堆             -> 对应物理地址内存池的一块内存
        ----------------------------

        作者的做法应该是没有考虑multitask的，而且在用户页表中，除了栈，代码和数据，其他部分并不是无效的，而是线性映射的，而且我们
        暂时没有缺页的机制。假设用户程序的代码+数据为x, 那么只有 0x3fb000~0x3ff000, 0x400000~0x400000+x 是用户的，其他都是
        线性映射到物理地址的。而内核的代码和数据是从0x100000开始的，这也是中断后，在用户页表的基础上可以跳到内核的代码的原因，因为
        不冲突。是在Linux上应该不是这么做的。

        我们通过gdb发现 int 0x80 后有三个寄存器改变，一个是esp, 一个是eip，一个是ss, 其中eip应该是通过访问 idt_table 的 
        offset 0x80 得到的，idt_table的地址存在idtr寄存器。但是esp和ss是哪来的呢？答案是每次iret，cpu都会将当前的esp和ss
        存到tss的esp0和ss0里，而tss的地址在tr寄存器里。(ss -> stack segment)
        
        我很好奇，程序一开始的esp在哪里？让我从boot程序开始分析:
        在boot程序刚被加载进内存位置0x7c00时，也就是一开始，寄存器状态如下:
          esp   0x6f08
          eip   0x7c00
          cs... 0x0
          cr3   0x0
        可以看见此时段寄存器和页表寄存器都没有值，但是esp为什么是0x6f08？搜索 osdev 0x6f08好像能搜到，但这不重要。

        然后执行boot.asm的step2，这一步好像是在初始化段寄存器和esp，它将esp设置为0x7c00, 即把 0x0~0x7c00看作自己的栈。
          esp   0x7c00
          eip   0x7c50
          cs... 0x0
          cr0   0x10
          cr3   0x0

        然后执行load_protected，这一步启用了protected mode:
          esp   0x7c00
          eip   0x7c61
          cs... 0x0
          cr0   0x11
          cr3   0x0
        在这里可以看到cr0 = 0x11 = 0x10 | 0x01，也就是PT(Protected Enbale)

        启用保护模式后就是把内核代码加载到了起始为0x100000的内存里，然后跳转到0x100000。这里有一个点，我们不是直接跳到0x100000
        的，而是jmp CODE_SEG:0x100000，这里CODE_SEG为0x8，但是eip没有跳到0x100080，而是0x100000。这是因为一旦开启了保护模
        式，段寄存的含义就变成了gdt偏移量 | CPL。对于gdt里的内容，我们在gdt.c的encodeGdtEntry()中可以看到，gdt主要有三个数据，
        base, limit 和 type，base是指该段的起始地址，在类Linux内核中，我们忽略分段，因此base一般是0，limit分两种情况，一种是
        limit <= 65536，那么说明是real mode, 若 limit > 65536，说明是protected mode，此时我们将limit >> 12，也就是说我
        门默认分页，并且页大小为4kb，因此我们只要保存页数即能知道其真正的limit。我设置的CODE_SEG对应的gdt的base为0, 因此这就是
        CODE_SEG:0x100000直接跳到0x100000的原因。

        接下来是_start的初始部分，在这里甚至段寄存器，然后设置esp和ebp，新的栈是从0x200000起始的，这个栈是不是里代码和数据有点
        近了？

        接下来是启用A20 Line(详见54)，然后是 remap 8295 PIC(详见53)。

        记录一下，加载完gdt后寄存器的状态。
          esp   0x1fffe0
          eip   0x100615
          cs    0x8
          ss... 0x10
          cr3   0x0
        在刚才的部分，我们更新了栈指针为0x200000，更新了程序计数器到0x100000。

        接下来: 
          初始化内存管理
          加载文件系统
          初始化磁盘驱动
          初始化中断描述符表
          初始化tss
          初始化分页虚拟内存
          初始化系统调用
          初始化键盘

        然后进入user_land，加载我们的第一个用户程序，在初始化用户程序时，我们仅设置了task的registers中的一部分，ip设置为0x400
      000，ss设置为0x23，cs设置为0x1b，sp设置为0x3ff000。
        在iret的前一刻，我们记录下当前寄存器的状态:
          esp   0x1fffa4
          eip   0x1070ef
          cs    0x8
          ss    0x10
          ds... 0x23
          cr3   0x1413000
        从上面的寄存器状态可以看到，我们加载了ds等段寄存器，使其为用户数据段，同时加载了用户页表。不能直接修改cs/ip和ss/sp的值，
      要通过 iret + 栈 的方式来更改。
        接下来执行iret，我们看看寄存器的变化: 
          esp   0x3ff000
          eip   0x400000
          cs    0x1b
          ss... 0x23
          cr3   0x1413000
        可以看到，在iret后，修改了cs/ip和ss/sp，而这就是我们放到栈里的值。

        接下来我们记录int前的寄存器状态:
          esp   0x3feffc
          eip   0x400005
          cs    0x1b
          ss... 0x23
          cr3   0x1413000
        然后是执行完 int 0x80 后的状态:
          esp   0x5fffec
          eip   0x10500f
          cs    0x8
          ss    0x10
          ds... 0x23
          cr3   0x1413000
        可以看到，执行完中断后，cs/ip 和 ss/sp 又回到了内核状态，但是ds等段寄存器和页表没有换。那就有一个问题，int是如何直到内
      核的 ss/sp 的呢？答案是在我们的TSS存储了ss0和esp0，这里存储的是内核的 ss/sp；那 cs/ip 是如何找到的呢？答案是中断表的地址
      存在idtr里，通过中断号0x80找到对应的idt，idt里面存储了selector和handler函数的地址，分别是内核 cs/ip。

        执行完kernel_page()后，即 kernel_registers() + paging_switch(kernel_chunk)后，寄存器的状态如下:
        esp   0x5fffa4
        eip   0x101450
        cs    0x8
        ss... 0x10
        cr3   0x1004000
        所以有些寄存器时不能直接更改的，只能通过特殊的指令间接更改，比如 cs/ip, ss/sp，而其他的寄存器都是可以直接更改的。
        对于task_page()同样如此，它只能更改能够更改的寄存器，其他的要通过iret来更改。之所以在起始调用kernel_page()是为了让处理
      器完全进入内核态，在结尾调用task_page()是为了让其完全恢复用户态。因为特殊指令只会更改 cs/ip 和 ss/sp
        其实我有点怀疑，栈里的cs/ip 和 ss/sp是什么时候推进去的？是int吗？还是pusha?推到用户栈还是内核栈？应该是推到了内核栈，因
      为我们iret的上下文是在内核栈，要进入用户栈，而我们不知道用户栈在哪，如果cs/ip 和 ss/sp推到用户栈那则是矛盾的，我们在内核栈
      的环境下没办法利用这个信息。综上所述：int后，cs/ip 和 ss/sp被推到内核栈，但是这是int触发的还是pusha触发的？
        答案是由int触发的，pusha是将通用寄存器压入栈中，user_registers()只是设置了可以直接更改的段寄存器，并没有设置通用寄存器，
      因此我们通过pusha和popa来保存和恢复通用寄存器。
        因此，int做了三件事: 首先从tss那里获得 ss/sp 并切换内核栈，然后用户态的 ss/sp 和 cs/ip 压到内核栈，最后根据 idtr 和中
      断号，找到对应的idt，idt里存储了 cs/ip，切换到内核中断handler程序。
        iret做了两件事: 首先将当前的 ss/sp 存到tss，然后用栈里的 ss/sp 和 cs/ip 恢复到用户进程。
        当然，int和iret只是做了最特殊的那一部分，在handler程序中，还要做通用寄存器的保存和恢复，可修改段寄存器的更新，以及页表的
      切换。这下就是彻底搞懂中断了，只剩下一片乌云，那就是在我们的kernel中，是碰巧实现在用户页表下也能成功访问内核handler代码的，
      我想知道Linux是如何稳定并安全的实现这一点的。

52. Segmention
      之前我对段的理解不全面，这次彻底搞懂。
      段有两个语境，Real Mode 和 Protected Mode，CPU处于哪种模式由cr0的最低位决定。
      Real Mode:
        在Real Mode语境中，因为地址线的位数只有16位，但是内存却有4MB，因此想要访问到更多内存就引入了段式寻址，CS:IP代表CS*0x10
      +IP。每个段是64K, 加入段是0x1000，那段的基地址就是0x10000，段的范围就是0x10000~0x1FFFF。有了段式寻址，我们能访问到的最
      大地址就是0xffff0 + 0xffff = 0x10ffef，x86有6个段寄存器：
        CS  Code Segment  代码段
        DS  Data Segment  数据段
        SS  Stack Segment 栈段
        ES  Extra Segment 额外段
        FS \
        GS - General Purpose Segments 通用目的段         
        段寄存器不是显示使用的，而是在访存时会默认使用段寄存器，比如MOV[SI], AX, 其实就是[DS:SI]->AX。可能根据寄存器的不同或者
      是指令的不同会隐含不同的段寄存器，但是有一点是不变的，那就是在Real Mode，形成任何地址时都会涉及段寄存器。
        CS是段寄存器中最特殊的一个，其他的段寄存器都可以通过mov ds, ax或者pop ds这样显式地更改。只能通过如下几种方式更改CS:
          far jump: jmp 0x10:0x100, 这个并不是普通的跳转，而是一次far jump, 它在跳转到0x200的同时会修改CS为0x10
          far call: call 0x10:0x100, 与far jump相同，并把旧的CS/IP推到栈里
          int: 中断后，赋值Interrupt Vector Table中存储的CS和IP，然后将旧的EFLAGS和CS/IP等信息推到栈里
          far return: far call返回后，pop 栈里的CS/IP
          iret: 中断返回后，pop 栈里的CS/IP和EFLAGS等信息
        除了以上几个指令，没有其他方法能修改CS。

      Protected Mode:
        在保护模式下，分段被认为是过时的内存保护技术，更加好用的是分页，但是为了兼容之前的版本以及使用x86的某些功能，我们仍然要通过
      段来实现，起始想要忽略段的干扰也很简单，只需要将每个段的base都设置为0就可以了，这样就可以专心使用分页了。在保护模式中，段被包
      含在gdt中，除了段的描述外gdt还存储了很多其他信息，比如一些权限，比如在gdt offset的低两位存储了隔离级别，我们还可以通过gdt进
      入64位的long Mode。
        也就是说，在保护模式下有用的是gdt，段只是gdt中包含的一部分，而且是被忽略的那一部分。
        在Protect Mode中，段寄存器中存储的不是段的地址，而是selector, 所谓selector就是gdt表的偏移量，gdt存储了每个段的特征信
      息，包括base address, limit 和 descriptor type。 
        gdt中存储的具体信息:
          The base address of the segment            段的起始地址
          The default operation size in the segment  (16-bit/32-bit) 
          The privilege level of the descriptor      (Ring 0 -> Ring 3)
          The granularity                            (Segment limit is in byte/4kb units)
          The segment limit                          (The maximum legal offset within the segment)
          The segment presence                       (Is it present or not)
          The descriptor type                        (0 = system; 1 = code/data)
          The segment type                           (Code/Data/Read/Write/Accessed/Conforming/Non-Conforming/
                                                      Expand-Up/Expand-Down)
        如果gdt的descriptor type为0(0 = system), 那gdt就不是用来描述段的，而是一种特殊的门机制，用来描述LDT或TSS的位置，即
      base存储位置，limit存储大小。
        对于描述段的gdt，那么该段的范围就是[base, base + limit], 如果采用A:B的方式去访存，那么地址就是base(gdt[A]) + B,如
      果你使用的是call, jmp这些(上面由介绍修改CS的方法)，还会同时修改CS。
        其他规则和real mode相同，也就是说在访存时，会默认使用段寄存器，访问IP相关就用上base(gdt(cs)), 访问SP相关就加上base
      (gdt(ss)), 访问其他相关则加上base(gdt(ds))。但是，现代操作系统都使用分页，并自动忽略了段寻址，因此base都是0，limit都是
      0xFFFFF，只有其他的属性有所不同，亦或是类别不同(比如是LDT或TSS)。
        
      关于段有几个点要说明:
        1.段是可以彼此覆盖的
        2.CS,DS,ES,FS,GS,SS是彼此独立的
        3.CS不能被直接改变

      关于C的注释: 
        1.所有现代C编译器都是采用平面内存模型。如果你想在C语言中使用分段，那么就不能使用现代编译器编译你的程序。
        2.在此模型下，所有段都覆盖整个地址空间(在x86中是4GB)。本质上，我们忽略了A:B的A部分，这是因为大部分处理器都没有分段，编译
          器更好优化。
        3.你可以为每个特权集(通常是Ring 0 和 Ring 3)创建两个gdt描述符，一个用于Code，一个用于Data, 这两个gdt描述了完全相同的
          段，而且在属性上也仅有一位不同(即Code/Data位)，代码描述符加载到CS中，数据描述符则由其他所有段寄存器共用，既然两个描述
          符几乎相同，那么为什么要分成Code和Data呢？这是因为兼容分段的功能，x86无法舍弃分段，即使我们不使用分段，只使用属性也必须
          兼容x86的分段规则。
        
      总的来说，在Protected Mode中: 分段包含在gdt内，我们忽略分段，同时也兼容分段，并使用gdt中的其他属性。

53. 8259 PIC
    8259可编程控制器是x86体系最重要的芯片之一，没有它，x86就不会是中断驱动的体系结构。8259 PIC的功能是管理硬件中断，有了它CPU就
  不用轮询硬件设备，可以直接响应中断。
    在现代操作系统中，功能更强大的APIC已经取代旧的8259 PIC，因为要适配多核处理器。
    一开始IBM的PC只有一个PIC芯片，提供了8个IRQ，即中断。后来的PC/AT加入了第二个PIC芯片，然后将两个PIC芯片级联，总共能个处理15个
  IRQ。，这样的双PIC结构沿用至今，直到更高级的APIC出现。
    对于处理器来说，PIC也是外部设备，需要通过in和out来沟通。每个PIC芯片都有两个I/O port，分别是Command port和Data Port，即:
      Master Command Port:  0x20
      Master Data Port:     0x21
      Slave Command Port:   0xA0
      Slave Data Port:      0xA1
    对于PIC的编程，Real Mode 和 Protected Mode也有不同。
    Real Mode:
      IRQ 0~7 对应中断号 0x8~0xF
      IRQ 8~15 对应中断号 0x70~0x77
    Protected Mode:
      Intel的CPU有硬件异常，Intel保留了31个CPU异常，对应中断号0x00~0x1F(csapp上有介绍)。为了不与CPU异常冲突，我们需要remap
    PIC，通常的选择是将它们移动到可用范围的开始，即0x20为起始点，IRQ 0...0xF -> INT 0x20...0x28。这也是我们定时器中断的IRQ号
    是0, 但是在Handler中其中断号是0x20的原因。前31个中断号被CPU异常占了，我们remap RIP通常以0x20(即32)为起点。并且IRQ的中断
    号起点必须是8的倍数，因为要用低三位来识别是哪个ISR，所以0x20其实是一个一石二鸟的选择，既是8的倍数，也是可用范围的起点。
      在Protected Mode给PIC的第一个指令就是初始化指令，即outb(0x20, 0x11)。如果我们不进行outb(0x20, 0x11), 那后续的out都
    被理解成默认地设置mask，初始化后PIC会在data端口等待三个数据：
        1. vector offset 即中断号的起点
        2. 主从PIC如何相连
        3. 额外的环境信息，0x1代表8086 mode
      那么进入Protected Mode后remap PIC的代码就是:
        // 保存mask
        uint8_t a1 = inb(0x21);
        uint8_t a2 = inb(0xA1);
        // 初始化master PIC 和 Slave PIC
        outb(0x20, 0x11);
        outb(0xA0, 0x11);
        // 设置主从的 vector offset
        outb(0x21, 0x20);
        outb(0xA1, 0x28);
        // 主从PIC如何相连
        outb(0x21, 4);
        outb(0xA1, 2);
        // 额外的环境信息，8086 mode
        outb(0x21, 0x1);
        outb(0xA1, 0x1);
        // 恢复mask
        outb(0x21, a1);
        outb(0xA1, a2);
      对PIC的数据端口out默认是设置mask，mask类似Linux信号的阻塞，设置了哪一个中断的mask就忽略哪一个中断。
      PIC是什么？PIC怎么初始化？PIC如何设置mask？接触更高级的APIC

54. A20 Line:
    A20是第21个地址线。8086能访问1MB的内存，这就是说它有20根地址线，但是8086有一个怪癖，那就是"内存环绕"。简单来说就是以前的程序
  员目光短浅，为了让地址不超过1MB，干脆禁用第21根地址线，而之后发布的CPU都要兼容这一特性(我们开发的是基于x86的内核)，因此如果想要
  访问完整的32位或64位地址空间，首先要做的就是启用A20 Line。
    使用一些固定的in, out指令，可以快速启用A20 Line。
    in al, 0x92
    or al, 2
    out 0x92, al

55. Real Mode:
    Real Mode是一种简单的16位操作模式，存在于所有x86处理器上。Real Mode是第一个x86操作模式，在保护模式诞生之前，许多早期操作
  系统都是使用它。出于兼容的目的，所有x86的处理器都以实模式开始执行。即计算机开机，开始自检，将磁盘的第一个扇区加载到内存，开始执行，
  此时CPU就是Real Mode，如果想进入Protect Mode需要手动进行切换。
    CPU的状态完全是由其寄存器决定的，包括使用的是那一个页表，CPU当前是处于哪一个Rings等级，CPU此时是Real Mode还是Protect Mode,
  我们所说的切换进程，也只不过是切换CPU的寄存器状态。
    Real Mode相较于Protect Mode的好处和坏处：
    坏处:
        1. 可用内存不到1MB
        2. 没有基于硬件的内存保护(GDT)，也没有虚拟内存(没办法保护内存)
        3. 没有内置的安全机制来防止有漏洞或恶意的应用程序(没有Rings级别)
        4. 默认的CPU操作数长度只有16位。
        5. 提供的内存寻址模式相较于其他CPU模式更具限制性(只有直接和间接寻址?)
        6. 访问超过64KB的内存需要使用难以使用的段寄存器，即 段寄存器 << 16 + 偏移量，因为只有16位二进制数
    好处：
        1. 可以使用所有的BIOS驱动程序和中断
        2. 可以使用BIOS提供的所有高级的低级API集合
        3. 由于不用检查Rings等级和内存映射，Real Mode访问内存更快。

56. Protect Mode:
    自80826以来，保护模式就是现代英特尔处理器的主要操作模式，在80826之前都是Real Mode。在80386及更高版本上，32位保护模式允许
  使用多个虚拟地址空间，每个虚拟地址空间最多有4GB的可寻址内存；并使系统能够实施严格的内存和硬件IO保护(即没办法访问其他进程的内存，
  也没有办法修改IO端口的值), 以及通过Rings限制可用指令集。
    CPU是由BIOS启动的，一开始的模式是Real Mode。通过将CPU切换到Protect Mode能够释放CPU的最大威能，但是在Protect Mode下没
  办法使用大部分的BIOS中断。
    那么如何进入保护模式呢？
    1. 禁用中断
    2. 启用A20 Line
    3. 加载GDT以及段选择器
    决定CPU处于Real Mode还是Protect Mode的最关键因素在于cr0的最低位，1代表Protect Mode，0代表Real Mode。
    Protect Mode和Real Mode的区别就是1.内存空间增长，2.能够使用虚拟内存，3.使用Rings限制可用指令集
    正是有了Protect Mode，才有了我们熟悉的Kernel，User land，MultiTask，虚拟内存 这些东西。

57. x86 registers
    之前我对x86的寄存器都是模糊不清的，不清楚都有哪些寄存器，不清楚这些寄存器都是干什么的，不能这样。(注: e是32位的意思)
  第一部分：通用目的寄存器
    eax   Accumulator         累加器
    ebx   Base          
    ecx   Counter             循环计数器
    edx   Data
    esi   Source        
    edi   Destination   
    esp   Stack Pointer       栈指针
    ebp   Stack Base Pointer  栈基址针

  第二部分: 指针寄存器
    eip   Instruction Pointer 指令指针

  第三部分: 段寄存器
    CS    Code Segment              代码段，涉及ip的访存会用到
    SS    Stack Segment             栈段，涉及sp的访存会用到
    DS    Data Segment              数据段，其他访存要用到
    ES    Extra Segment             额外段，功能未知
    FS    General Purpose F Segment 通用目的F段
    GS    General Purpose G Segment 通用目的G段

  第四部分: EFLAGS Register
   Bit   Label  Description                       
    0 	  CF 	  Carry flag                      进位
    2 	  PF 	  Parity flag                     奇偶校验
    4 	  AF 	  Auxiliary flag                  辅助?
    6 	  ZF 	  Zero flag                       零
    7 	  SF 	  Sign flag                       符号
    8 	  TF 	  Trap flag                       陷阱?
    9 	  IF 	  Interrupt enable flag           中断启用
    10 	  DF 	  Direction flag                  方向?
    11 	  OF 	  Overflow flag                   溢出
    12-13 IOPL 	I/O privilege level             I/O特权级别?
    14 	  NT 	  Nested task flag                递归
    16 	  RF 	  Resume flag                     恢复?
    17 	  VM 	  Virtual 8086 mode flag          虚拟8086模式?
    18 	  AC 	  Alignment check                 字节对齐检查
    19 	  VIF 	Virtual interrupt flag          虚拟中断?
    20 	  VIP 	Virtual interrupt pending       虚拟中断挂起?
    21 	  ID 	  Able to use CPUID instruction   能够使用CPUID指令

  第五部分: Control Registers (cr0 的 cr 就是control的意思)
    CR0:
      Bit Label 	Description
      0 	PE 	  Protected Mode Enable   保护模式
      1 	MP 	  Monitor co-processor    显示器协处理器?
      2 	EM 	  x87 FPU Emulation       x87 FPU 仿真器?
      3 	TS 	  Task switched           任务切换
      4 	ET 	  Extension type          扩展类型?
      5 	NE 	  Numeric error           数字错误?
      16 	WP 	  Write protect           写保护?
      18 	AM 	  Alignment mask          字节对齐标志
      29 	NW 	  Not-write through       未写入
      30 	CD 	  Cache disable           缓存禁用
      31 	PG 	  Paging                  分页

    CR1:
      保留，CPU尝试访问它时将引发#UD异常

    CR2:
      0-31 (63) 	PFLA 	Page Fault Linear Address   页面错误线性地址?

    CR3:
      Bit 	   Label 	Description 	                  PAE 	         Long Mode
      3 	      PWT 	Page-level Write-Through 	    (Not used) 	  (Not used if bit 17 of CR4 is 1)
      4 	      PCD 	Page-level Cache Disable 	    (Not used) 	  (Not used if bit 17 of CR4 is 1)
      12-31(63) PDBR 	Page Directory Base Register 	Base of PDPT 	Base of PML4T/PML5T 
      PWT是页表等级的写标志
      PCD是页表等级的缓存禁用
      PDBR是页表基址

    CR4:
      Bit 	Label 	D       escription
        0 	VME 	      Virtual 8086 Mode Extensions
        1 	PVI 	      Protected-mode Virtual Interrupts
        2 	TSD 	      Time Stamp Disable
        3 	DE 	        Debugging Extensions
        4 	PSE 	      Page Size Extension
        5 	PAE 	      Physical Address Extension
        6 	MCE 	      Machine Check Exception
        7 	PGE 	      Page Global Enabled
        8 	PCE 	      Performance-Monitoring Counter enable
        9 	OSFXSR 	    Operating system support for FXSAVE and FXRSTOR instructions
        10 	OSXMMEXCPT  Operating System Support for Unmasked SIMD Floating-Point Exceptions
        11 	UMIP 	      User-Mode Instruction Prevention (if set, #GP on SGDT, SIDT, SLDT, SMSW, and STR 
                      instructions when CPL > 0)
        12 	LA57 	      57-bit linear addresses (if set, the processor uses 5-level paging otherwise it uses
                      uses 4-level paging)
        13 	VMXE 	      Virtual Machine Extensions Enable
        14 	SMXE 	      Safer Mode Extensions Enable
        16 	FSGSBASE 	  Enables the instructions RDFSBASE, RDGSBASE, WRFSBASE, and WRGSBASE
        17 	PCIDE 	    PCID Enable
        18 	OSXSAVE 	  XSAVE and Processor Extended States Enable
        20 	SMEP 	      Supervisor Mode Execution Protection Enable
        21 	SMAP 	      Supervisor Mode Access Prevention Enable
        22 	PKE 	      Protection Key Enable
        23 	CET 	      Control-flow Enforcement Technology
        24 	PKS 	      Enable Protection Keys for Supervisor-Mode Pages
      作用未知???

    CR5-CR7:
      保留，和CR1一样。

    CR8:
      Bit 	Label 	Description
      0-3 	TPL 	Task Priority Level   任务优先级?

  第六部分: Extended Control Registers
    XCR0:
      Bit 	Label 	Description
      0 	X87 	x87 FPU/MMX support (must be 1)
      1 	SSE 	XSAVE support for MXCSR and XMM registers
      2 	AVX 	AVX enabled and XSAVE support for upper halves of YMM registers
      3 	BNDREG 	MPX enabled and XSAVE support for BND0-BND3 registers
      4 	BNDCSR 	MPX enabled and XSAVE support for BNDCFGU and BNDSTATUS registers
      5 	opmask 	AVX-512 enabled and XSAVE support for opmask registers k0-k7
      6 	ZMM_Hi256 	AVX-512 enabled and XSAVE support for upper halves of lower ZMM registers
      7 	Hi16_ZMM 	AVX-512 enabled and XSAVE support for upper ZMM registers
      9 	PKRU 	XSAVE support for PKRU register 
    XCR0只有CR4的18位为1时才会启用。XCR0好像是和浮点数运算和视频服务相关的，因为我看到了AVX，XMM，YMM之类的字段。

  第七部分: Debug Registers
    DR0-DR3:
      包含最多4个断点位置，如果启用分页，则转换为物理地址。原来由专门的寄存器来存储断点。

    DR6:
      It permits the debugger to determine which debug conditions have occurred.
      Bits 0 through 3 indicates, when set, that it's associated breakpoint condition was met when a debug exception was generated.
      Bit 13 indicates that the next instruction in the instruction stream accesses one of the debug registers.
      Bit 14 indicates (when set) that the debug exception was triggered by the single-step execution mode (enabled with TF bit in EFLAGS).
      Bit 15 indicates (when set) that the debug instruction resulted from a task switch where T flag in the TSS of target task was set.
      Bit 16 indicates (when clear) that the debug exception or breakpoint exception occured inside an RTM region.
    作用未知???

    DR7:
      Bit 	Description
      0 	    Local DR0 breakpoint
      1 	    Global DR0 breakpoint
      2   	  Local DR1 breakpoint
      3 	    Global DR1 breakpoint
      4 	    Local DR2 breakpoint
      5 	    Global DR2 breakpoint
      6 	    Local DR3 breakpoint
      7 	    Global DR3 breakpoint
      16-17 	Conditions for DR0
      18-19 	Size of DR0 breakpoint
      20-21 	Conditions for DR1
      22-23 	Size of DR1 breakpoint
      24-25 	Conditions for DR2
      26-27 	Size of DR2 breakpoint
      28-29 	Conditions for DR3
      30-31 	Size of DR3 breakpoint 
      CR7标记断点的类型，local断点代表禁用硬件任务切换，global则不会。感觉禁用硬件切换有点暴力，只有在特殊场景才会用到，即使禁
    用硬件任务切换进程页感知不到，难道在切换任务时也会保存恢复debug寄存器吗？

  第七部分: Test Registers
    Name 	      Description
    TR3 - TR5 	Undocumented      未记录
    TR6 	Test  command register  命令寄存器
    TR7 	Test  data register     数据寄存器

  第八部分: Protected Mode Registers
    GDTR: 
      Bits 	Label 	Description
      0-15 	Limit 	(Size of GDT) - 1
      16-47 Base 	  Starting address of GDT
    GDTR里存的其实是GDT描述符的地址，GDT描述符里村的才是上面的Limit和Base, Base是gdt表的地址，Limit是gdt表的大小。

    LDTR:
      Bits 	Label 	Description
      0-15 	Limit 	(Size of LDT) - 1
      16-47 Base 	  Starting address of LDT
    LDTR里是什么未知，是TSS吗？我想知道ltr对应的是哪个寄存器，是Test Register吗？不能吧

    IDTR:
      Bits 	Label 	Description
      0-15 	Limit 	(Size of IDT) - 1
      16-47 	Base 	Starting address of IDT
    同GDTR一样，IDTR里存储的是idt描述符的地址，idt描述符里存储的是Base和Limit，Base里存的是idt表的地址，Limit里存的是idt表
    的大小。

    这下就知道x86里都有哪些寄存器了，并且也知道了大致的功能，不会再胡思乱想了。

58. ELF文件
    ELF文件的优点是它可以用来链接。通过symbol来链接，全局变量和函数会被识别为symbol, add-symbol-file中的symbol也是这个意思。
  kernel真的有必要加入ELF文件吗？我觉得是有必要的，因为exec()系统调用即加载需要一个统一的文件格式，而便于链接、功能强大的ELF就是
  首选。在我看来动态链接是比较难的，而作者好像就是要实现动态链接，dokidoki。动态库内的代码是多进程共享的，但是这个函数必须是可重入
  函数，感觉只读不写共享数据也是可行的。
    ELF文件的Program header table标注了只读部分和可写部分，其中.text和.rodata是只读的，其他是可写的。而Section header tab
  le标注了每个段的位置，以上信息可以用来mmap映射。ELF文件还有string table，里面存储的不是字符串常量，而是段名或者符号名。program
  header帮助我们加载程序，即mmap映射，也可用用section header来加载。再加载时我们可以先把ELF文件的header加载到内存，根据header
  来进行映射，而不是将整个程序都加载到内存。
    我们实现的只是一个ELF的加载器，而不是基于ELF的链接器，那是编译器做的。作者还说目前是一个静态ELF加载器，将来会做动态的吗？如果
  可以，我希望kernel的加载器是更高级的动态ELF加载器。

59. 安装了两个工具
    dumpelf 可以解析elf文件的二进制信息，主要是显示各个Header内的参数，能帮助我们理解elf文件的结构
    readelf -a 可以显示elf文件的所有信息，非常全面且易读

待办: 
    1. 中断返回发生了什么?
    2. 用户页表基础下跳到内核代码时，发生了什么?
    3. 阅读sem_wait()和sem_post()的源码
    4. 重看88的gdb调试部分，调试键盘的同时学习gdb
